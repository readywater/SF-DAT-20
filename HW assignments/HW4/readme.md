# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) HW #4: Random Forest and Boosting
DS | Unit Project 4

### PROMPT

In this project, you will use Random Forest and boosting technique to improve prediction of Spam/Ham dataset. Ealier in this class we were able to reduce misclassification error down to 8.2%. This time we would like to beat this record! 

The champion of this project - the one who achieves the lowest 10-fold cross-validation error will receive a **one Dollar Bill** award. Moreover, his/her solution will be posted as proposed solution!

**Goal:** An ipython notebook that provides a great and predictable model. 

---

### DELIVERABLES

#### IPython Notebook Exploratory Analysis

- **Requirements:**
  - Read in your dataset
  - apply random forest to dataset. Tune it with as many vaiations in your parameters.
  - use 10 fold cross-validation to measure your error. 
  - apply boosting algorithm and tune all necessary parameters to achieve the best result. 
  - use 10 fold corss-validation to evaluate your error.
  - report your the best random forest and the best boosting result you found.
  - repot your lowest classification error along side the tuning parameters of those specific parameters.  
  - list your most important variables. 


- **Submission:**
    - This project is due on Mar 21st 2016 at 6:30PM. Please submit it to Michael Twardos via Slack.

---

### TIMELINE

| Deadline | Deliverable| Description |
|:-:|---|---|
| Lesson 15 | HW 4  | Random Forest and Boosting  |

---

### EVALUATION

Your project will be assessed using the following standards:

- finding a random forest with an error lower than logistic regression
- finding a boosting algorithm that performes better than logistic regression
- sharing best results associated with each algorithm along side the optimal tuning parameters found. 



Requirements for these standards will be assessed using the scale below:

    Score | Expectations
    ----- | ------------
    **0** | _Incomplete._
    **1** | _Does not meet expectations._
    **2** | _Meets expectations, good job!_
    **3** | _Exceeds expectations, you wonderful creature, you!_

While your total score is a helpful gauge of whether you've met overall project goals, __specific scores are more important__ since they'll show you where to focus your efforts in the future!

---

### RESOURCES

#### Dataset  
In this project we are going to use 'spambase.cvs' dataset. This dataset has been earlier used for Logistic Regression model. 

#### Starter code
For this project we will be using an IPython notebook. 




---

