{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  prestige\n",
      "0      0  380  3.61         3\n",
      "1      1  660  3.67         3\n",
      "2      1  800  4.00         1\n",
      "3      1  640  3.19         4\n",
      "4      0  520  2.93         4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317380</td>\n",
       "      <td>587.858942</td>\n",
       "      <td>3.392242</td>\n",
       "      <td>2.488665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466044</td>\n",
       "      <td>115.717787</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.947083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa    prestige\n",
       "count  397.000000  397.000000  397.000000  397.000000\n",
       "mean     0.317380  587.858942    3.392242    2.488665\n",
       "std      0.466044  115.717787    0.380208    0.947083\n",
       "min      0.000000  220.000000    2.260000    1.000000\n",
       "25%      0.000000  520.000000    3.130000    2.000000\n",
       "50%      0.000000  580.000000    3.400000    2.000000\n",
       "75%      1.000000  660.000000    3.670000    3.000000\n",
       "max      1.000000  800.000000    4.000000    4.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/ga-students/SF-DAT-20/master/HW%20assignments/HW2/admissions.csv\"\n",
    "AdmissionData = pd.read_csv(url)\n",
    "print(AdmissionData.head(5))\n",
    "# Let's get rid of Missing values - there are only a few missing values so, let's drop them all\n",
    "AdmissionData.dropna(inplace = True)\n",
    "AdmissionData.describe() # Only 3 rows are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige  prestige_1.0  prestige_2.0  prestige_3.0\n",
       "0      0  380  3.61         3             0             0             1\n",
       "1      1  660  3.67         3             0             0             1\n",
       "2      1  800  4.00         1             1             0             0\n",
       "3      1  640  3.19         4             0             0             0\n",
       "4      0  520  2.93         4             0             0             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrestigeDummy = pd.get_dummies(AdmissionData.prestige, prefix = 'prestige')\n",
    "del PrestigeDummy['prestige_4.0']\n",
    "AdmissionData = pd.concat([AdmissionData, PrestigeDummy], axis=1)\n",
    "AdmissionData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "y = AdmissionData['admit']\n",
    "X = AdmissionData[['gre','gpa','prestige_1.0','prestige_2.0','prestige_3.0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.58889206e-03   1.84632255e-04   1.16761197e+00   5.26947990e-01\n",
      "   -3.80822672e-02]]\n",
      "[-2.07018745]\n"
     ]
    }
   ],
   "source": [
    "lm.fit(X,y)\n",
    "print lm.coef_\n",
    "print lm.intercept_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we learn from these coefficients (assume they are all significant)?\n",
    "\n",
    "Higher GPA and higher GRE adds to odds of admission. The same story is true for prestige. The higher the prestige of your undergraduate school the more your chance of getting admitted. We are going to interpret the coefficients in more detail later.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In comparison to the person who is graduated from a tier 4 school (i.e. prestige = 4), what are the odds of a person who has graduated from a top level school to get admitted to UCLA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21430760315\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.exp(1.16761197)  - 1)\n",
    "#Her odds of admission is 221% more than a person who is graduated from a \n",
    "#tier 4 school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student A and Student B are graduated from same school, have same background and same GPA. The only difference between the two is their GRE score. Student A's GPA is 50 scores better. What is the difference of odds of admission for these two students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0826860101613\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(50*0.0015889 ) - 1)\n",
    "#Student A have 8.26% better odds than student B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the probability of a student who came from a second tier school to get admitted to UCLA if her GPA is 3.5, GRE Score is 650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[ 0.62476273  0.37523727]]\n"
     ]
    }
   ],
   "source": [
    "x1 = [[650,3.5,0,1,0]]\n",
    "print(lm.predict(x1))  #It is more likely that she will not get admitted\n",
    "print(lm.predict_proba(x1)) #Probability of Admission is only 37.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's calculate cross-validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80487805  0.575       0.725       0.675       0.7         0.675\n",
      "  0.69230769  0.64102564  0.71794872  0.66666667]\n",
      "0.687282676673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "print(cross_val_score(lm,X,y,cv=10))\n",
    "#cross_val_score(model,inputs,output,cv = k-fold).mean()\n",
    "print(cross_val_score(lm,X,y,cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[256, 104],\n",
       "       [ 15,  22]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_hat = lm.predict(X)\n",
    "confusion_matrix(y_hat,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try testing and plotting CV Scores with different C values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1124de810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEQCAYAAACwSgOGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWTfOTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110f6ab90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Try testing and plo\n",
    "c_list = np.logspace(-10,10,21) \n",
    "c_index = np.linspace(-10,10,21)\n",
    "#C is just the inverse of Lambda - the smaller the C - the stronger the\n",
    "#regulatization. The smaller C's choose less variables\n",
    "cv_scores = []\n",
    "for c_score in c_list:\n",
    "    lm = LogisticRegression(C = c_score)\n",
    "    cv_scores.append(cross_val_score(lm,X,y,cv=10).mean())\n",
    "\n",
    "\n",
    "C_Choice_df = pd.DataFrame({'cv_scores': cv_scores ,'Log_C': c_index })\n",
    "C_Choice_df.plot(x ='Log_C',y = 'cv_scores' )\n",
    "# our choice is C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00208211  0.63233015  1.46818076  0.79139489  0.15518328]]\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression(C = 10)\n",
    "lm.fit(X,y)\n",
    "print(lm.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IF YOU WAN TO MAKE COEFFICIENTS RELEVANT - YOU MUST STANDARDIZE YOUR DATA FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Standardize(X):\n",
    "    X_Max = X.max()\n",
    "    X_Min = X.min()\n",
    "    X_Standardized = (X-X_Min)/(X_Max - X_Min)\n",
    "    return X_Standardized\n",
    "\n",
    "#Please try it yourself\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
